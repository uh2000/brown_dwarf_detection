{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and find the different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           HD 203977\n",
       "sp_type             A0\n",
       "RAdeg        321.20044\n",
       "DEdeg        25.880459\n",
       "PS1gmag            NaN\n",
       "e_PS1gmag          NaN\n",
       "PS1rmag         7.6116\n",
       "e_PS1rmag        0.001\n",
       "PS1imag            NaN\n",
       "e_PS1imag          NaN\n",
       "PS1zmag         7.5167\n",
       "e_PS1zmag        0.001\n",
       "PS1ymag        13.5874\n",
       "e_PS1ymag       0.0028\n",
       "W1mag             6.88\n",
       "W2mag            6.919\n",
       "W3mag            6.946\n",
       "W4mag            6.484\n",
       "e_W1mag          0.059\n",
       "e_W2mag           0.02\n",
       "e_W3mag          0.016\n",
       "e_W4mag          0.059\n",
       "Jmag             6.896\n",
       "Hmag             6.921\n",
       "Kmag             6.932\n",
       "e_Jmag           0.026\n",
       "e_Hmag           0.024\n",
       "e_Kmag           0.016\n",
       "label                0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = \".\\original_dataset\\dataset_bd_wnames.csv\" #Windows\n",
    "data_path = \"original_dataset/dataset_bd_wnames.csv\"  #MACos\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()\n",
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ID', 'sp_type', 'RAdeg', 'DEdeg', 'PS1gmag', 'e_PS1gmag', 'PS1rmag',\n",
       "        'e_PS1rmag', 'PS1imag', 'e_PS1imag', 'PS1zmag', 'e_PS1zmag', 'PS1ymag',\n",
       "        'e_PS1ymag', 'W1mag', 'W2mag', 'W3mag', 'W4mag', 'e_W1mag', 'e_W2mag',\n",
       "        'e_W3mag', 'e_W4mag', 'Jmag', 'Hmag', 'Kmag', 'e_Jmag', 'e_Hmag',\n",
       "        'e_Kmag', 'label'],\n",
       "       dtype='object'),\n",
       " (5669, 29),\n",
       " 1598)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns, df.shape, len(df[df[\"label\"]==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sp_type</th>\n",
       "      <th>RAdeg</th>\n",
       "      <th>DEdeg</th>\n",
       "      <th>PS1gmag</th>\n",
       "      <th>e_PS1gmag</th>\n",
       "      <th>PS1rmag</th>\n",
       "      <th>e_PS1rmag</th>\n",
       "      <th>PS1imag</th>\n",
       "      <th>e_PS1imag</th>\n",
       "      <th>...</th>\n",
       "      <th>e_W2mag</th>\n",
       "      <th>e_W3mag</th>\n",
       "      <th>e_W4mag</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>Hmag</th>\n",
       "      <th>Kmag</th>\n",
       "      <th>e_Jmag</th>\n",
       "      <th>e_Hmag</th>\n",
       "      <th>e_Kmag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*  11 Peg</td>\n",
       "      <td>A0V</td>\n",
       "      <td>326.80817</td>\n",
       "      <td>2.686124</td>\n",
       "      <td>5.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.044</td>\n",
       "      <td>5.562</td>\n",
       "      <td>5.539</td>\n",
       "      <td>5.479</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD 203977</td>\n",
       "      <td>A0</td>\n",
       "      <td>321.20044</td>\n",
       "      <td>25.880459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6116</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.059</td>\n",
       "      <td>6.896</td>\n",
       "      <td>6.921</td>\n",
       "      <td>6.932</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD  83162</td>\n",
       "      <td>A0III/IV</td>\n",
       "      <td>144.03845</td>\n",
       "      <td>-12.459262</td>\n",
       "      <td>10.512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.408</td>\n",
       "      <td>10.400</td>\n",
       "      <td>10.378</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*  10 Boo</td>\n",
       "      <td>A0Vs</td>\n",
       "      <td>209.66217</td>\n",
       "      <td>21.696203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8603</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.037</td>\n",
       "      <td>5.671</td>\n",
       "      <td>5.717</td>\n",
       "      <td>5.704</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD  27616</td>\n",
       "      <td>A0V</td>\n",
       "      <td>65.16255</td>\n",
       "      <td>-20.639620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3206</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.036</td>\n",
       "      <td>5.430</td>\n",
       "      <td>5.402</td>\n",
       "      <td>5.333</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   sp_type      RAdeg      DEdeg  PS1gmag  e_PS1gmag  PS1rmag  \\\n",
       "0  *  11 Peg       A0V  326.80817   2.686124    5.556        NaN   5.7600   \n",
       "1  HD 203977        A0  321.20044  25.880459      NaN        NaN   7.6116   \n",
       "2  HD  83162  A0III/IV  144.03845 -12.459262   10.512        NaN  10.6920   \n",
       "3  *  10 Boo      A0Vs  209.66217  21.696203      NaN        NaN      NaN   \n",
       "4  HD  27616       A0V   65.16255 -20.639620      NaN        NaN      NaN   \n",
       "\n",
       "   e_PS1rmag  PS1imag  e_PS1imag  ...  e_W2mag  e_W3mag  e_W4mag    Jmag  \\\n",
       "0        NaN   5.9470        NaN  ...    0.050    0.015    0.044   5.562   \n",
       "1      0.001      NaN        NaN  ...    0.020    0.016    0.059   6.896   \n",
       "2        NaN  10.8660        NaN  ...    0.020    0.074      NaN  10.408   \n",
       "3        NaN   6.8603     0.1042  ...    0.046    0.015    0.037   5.671   \n",
       "4        NaN   6.3206     0.0000  ...    0.072    0.015    0.036   5.430   \n",
       "\n",
       "     Hmag    Kmag  e_Jmag  e_Hmag  e_Kmag  label  \n",
       "0   5.539   5.479   0.017   0.026   0.020      0  \n",
       "1   6.921   6.932   0.026   0.024   0.016      0  \n",
       "2  10.400  10.378   0.026   0.021   0.023      0  \n",
       "3   5.717   5.704   0.023   0.063   0.020      0  \n",
       "4   5.402   5.333   0.054   0.036   0.017      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values with the mean of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ID', 'sp_type', 'RAdeg', 'DEdeg', 'PS1gmag', 'e_PS1gmag', 'PS1rmag',\n",
       "        'e_PS1rmag', 'PS1imag', 'e_PS1imag', 'PS1zmag', 'e_PS1zmag', 'PS1ymag',\n",
       "        'e_PS1ymag', 'W1mag', 'W2mag', 'W3mag', 'W4mag', 'e_W1mag', 'e_W2mag',\n",
       "        'e_W3mag', 'e_W4mag', 'Jmag', 'Hmag', 'Kmag', 'e_Jmag', 'e_Hmag',\n",
       "        'e_Kmag', 'label'],\n",
       "       dtype='object'),\n",
       " (5669, 29))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if column in [\"ID\", \"sp_type\"]: #Skipping these\n",
    "        continue\n",
    "  \n",
    "    df[column] = df[column].fillna(df[column].mean()) #Imputing NA values with mean\n",
    "\n",
    "df.head()\n",
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the vector \"sp_type\" as it is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       sp_type       RAdeg      DEdeg   PS1gmag  e_PS1gmag    PS1rmag  \\\n",
       "0           0  326.808170   2.686124   5.55600    0.02303   5.760000   \n",
       "1           1  321.200440  25.880459  15.12594    0.02303   7.611600   \n",
       "2           2  144.038450 -12.459262  10.51200    0.02303  10.692000   \n",
       "3           3  209.662170  21.696203  15.12594    0.02303  14.982256   \n",
       "4           0   65.162550 -20.639620  15.12594    0.02303  14.982256   \n",
       "...       ...         ...        ...       ...        ...        ...   \n",
       "5664      502   13.245956  49.443574   9.12270    0.23470   9.182300   \n",
       "5665      502   29.647854  48.432832  15.12594    0.02303   9.553800   \n",
       "5666      502  346.990957  54.326940  15.12594    0.02303   9.840500   \n",
       "5667      503  331.173131  46.427253  10.49150    0.06300  10.253800   \n",
       "5668      503  321.694044  43.812346  15.12594    0.02303   7.847700   \n",
       "\n",
       "      e_PS1rmag    PS1imag  e_PS1imag   PS1zmag  ...  e_W2mag  e_W3mag  \\\n",
       "0      0.027126   5.947000   0.022877   6.07200  ...    0.050    0.015   \n",
       "1      0.001000  14.918063   0.022877   7.51670  ...    0.020    0.016   \n",
       "2      0.027126  10.866000   0.022877  10.98900  ...    0.020    0.074   \n",
       "3      0.027126   6.860300   0.104200  14.64794  ...    0.046    0.015   \n",
       "4      0.027126   6.320600   0.000000   5.95040  ...    0.072    0.015   \n",
       "...         ...        ...        ...       ...  ...      ...      ...   \n",
       "5664   0.001000  14.918063   0.022877   9.00660  ...    0.019    0.021   \n",
       "5665   0.001000  14.918063   0.022877  10.72530  ...    0.019    0.026   \n",
       "5666   0.001000   9.202500   0.001000  10.10890  ...    0.020    0.030   \n",
       "5667   0.023900  10.005700   0.007400  10.44180  ...    0.020    0.033   \n",
       "5668   0.377700  14.918063   0.022877   8.16650  ...    0.020    0.017   \n",
       "\n",
       "       e_W4mag    Jmag    Hmag    Kmag  e_Jmag  e_Hmag  e_Kmag  label  \n",
       "0     0.044000   5.562   5.539   5.479   0.017   0.026   0.020      0  \n",
       "1     0.059000   6.896   6.921   6.932   0.026   0.024   0.016      0  \n",
       "2     0.099197  10.408  10.400  10.378   0.026   0.021   0.023      0  \n",
       "3     0.037000   5.671   5.717   5.704   0.023   0.063   0.020      0  \n",
       "4     0.036000   5.430   5.402   5.333   0.054   0.036   0.017      0  \n",
       "...        ...     ...     ...     ...     ...     ...     ...    ...  \n",
       "5664  0.144000   8.358   8.389   8.398   0.027   0.017   0.016      0  \n",
       "5665  0.297000   8.778   8.804   8.766   0.021   0.016   0.020      0  \n",
       "5666  0.327000   9.180   9.187   9.180   0.021   0.020   0.022      0  \n",
       "5667  0.099197   9.693   9.678   9.622   0.024   0.029   0.023      0  \n",
       "5668  0.115000   7.248   7.309   7.281   0.023   0.042   0.020      0  \n",
       "\n",
       "[5669 rows x 28 columns]>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('ID', axis=1)\n",
    "\n",
    "\n",
    "unique_values =len(X[\"sp_type\"].unique()) # 504\n",
    "\n",
    "X.shape, unique_values\n",
    "\n",
    "X['sp_type'], _ = pd.factorize(X['sp_type'])\n",
    "X.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe/array into data and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5669, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5669, 27), (5669,))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "y = X[\"label\"]\n",
    "X = X.drop(columns=[\"label\"])\n",
    "\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4535, 27), (4535,), (1134, 27), (1134,))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,  X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA to find the five vectors with the most variance, five is choosen arbitrarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.51264640e+02,  1.82493718e+01,  7.28737180e+00,\n",
       "          8.30797028e+00, -6.61689866e-03],\n",
       "        [ 1.39461917e+02,  1.12901286e+02,  1.04089343e+01,\n",
       "         -5.28225451e+00, -2.38794792e+00],\n",
       "        [ 1.81468796e+02, -5.90718656e+01, -3.14832852e+01,\n",
       "         -1.04027885e+01, -9.59790499e-01],\n",
       "        ...,\n",
       "        [-1.39997413e+02, -1.50195145e+02,  6.69641822e+00,\n",
       "          7.22258379e+00, -1.79487759e+00],\n",
       "        [ 3.72962926e+01, -2.06833593e+02, -9.25752173e+00,\n",
       "          9.88382057e+00, -1.52042602e+00],\n",
       "        [-2.48384563e+01,  8.94239391e+01, -1.03258346e+01,\n",
       "          2.13656546e+00, -1.18854750e+00]]),\n",
       " array([[-119.34465049,   13.35944633,  -17.64422317,   -4.65645822,\n",
       "            2.12184501],\n",
       "        [ 140.33428152, -213.55759905,   -2.34994964,    4.65875345,\n",
       "           -1.66764144],\n",
       "        [-158.95872546,   22.47732497,  -13.7876654 ,   -3.76555343,\n",
       "            0.3499343 ],\n",
       "        ...,\n",
       "        [ 176.47823442,  -25.79159391,  -32.05989098,   -6.90211547,\n",
       "            3.79465807],\n",
       "        [-121.58943188,   52.77733371,   26.58817682,    9.6242399 ,\n",
       "            0.8051    ],\n",
       "        [  26.95430008, -115.2357109 ,   -5.66263362,   -1.04531212,\n",
       "           -3.95740431]]))"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset wit respect to the traning data X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4535, 5), (1134, 5), (4535,), (1134,))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test) \"\"\"\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape, y_test.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data with respect to the training data X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4535, 5), (1134, 5), (4535,), (1134,))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4535, 5), (1134, 5), (4535,), (1134,))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net for binary classification 5x64x32x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.28440276197564435\n",
      "Epoch 2, Loss: 0.09712533348462951\n",
      "Epoch 3, Loss: 0.057771437919475664\n",
      "Epoch 4, Loss: 0.036573446250822345\n",
      "Epoch 5, Loss: 0.0251651680700376\n",
      "Epoch 6, Loss: 0.019137478846741815\n",
      "Epoch 7, Loss: 0.015854209484401305\n",
      "Epoch 8, Loss: 0.014588884955180258\n",
      "Epoch 9, Loss: 0.013910296571467229\n",
      "Epoch 10, Loss: 0.011243232268869589\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# Convert numpy arrays or pandas DataFrames to PyTorch tensors if needed\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# Defining a simple neural network class for binary classification\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()        # ReLU activation function\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output layer with single neuron (binary classification)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Apply sigmoid activation for binary classification of final output\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "input_size = X_train.shape[1]\n",
    "model = NeuralNet(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare data for training using DataLoader\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(dim=1)  # Remove extra dimension for binary classification\n",
    "        loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss per epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Example: Make predictions\n",
    "# Assuming X_test is your test data\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "model.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).int()  # Convert probabilities to binary predictions (0 or 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Save trained model\n",
    "# torch.save(model.state_dict(), './models/binary_classification_model.pth') #Windows\n",
    "torch.save(model.state_dict(), 'models/binary_classification_model.pth') #MACos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with F1 score as brown dwarfs are rare which is also true in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1619a0f40>\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/6b113_5n5jj0pcmjdn3s12ym0000gn/T/ipykernel_77498/983934941.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the trained model\n",
    "input_size = 5  # Assuming the input size based on X_train\n",
    "model = NeuralNet(input_size)\n",
    "# model.load_state_dict(torch.load('./models/binary_classification_model.pth'))  # Load the trained model state  (Windows)\n",
    "model.load_state_dict(torch.load('models/binary_classification_model.pth'))  # Load the trained model state (MACos)\n",
    "\n",
    "\n",
    "# Assuming X_test and y_test are your test data\n",
    "# Convert X_test and y_test to torch tensors if needed\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Prepare test dataset and dataloader\n",
    "batch_size = 64\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "\n",
    "# Evaluate the model on the test set using F1 score\n",
    "model.eval()  # Switch to evaluation mode\n",
    "y_true = []\n",
    "y_pred = []\n",
    "print(test_loader)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate F1 score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1134, 1134)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1134,), (1134, 1), torch.Size([1134]))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter  # Import SummaryWriter for TensorBoard\n",
    "writer = SummaryWriter('logs')  # Logs will be saved in the 'logs' directory\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_true.shape, y_pred.shape, y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Compute precision and recall\n",
    "precision = precision_score(y_true, y_pred, average='binary')  # Change average as needed\n",
    "recall = recall_score(y_true, y_pred, average='binary')  # Change average as needed\n",
    "\n",
    "accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[819,   0],\n",
       "       [  0, 315]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log evaluation metrics and confusion matrix to TensorBoard\n",
    "writer.add_scalar('Metrics/Accuracy', accuracy, global_step=0)\n",
    "writer.add_scalar('Metrics/Precision', precision, global_step=0)\n",
    "writer.add_scalar('Metrics/Recall', recall, global_step=0)\n",
    "writer.add_text('Confusion_Matrix', str(conf_matrix), global_step=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Close the writer\n",
    "writer.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "italia_project_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
