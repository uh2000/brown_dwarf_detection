{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the actual dataset from the matlab file given instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = \"original_dataset/ReadBrownDwarf.mat\"\n",
    "data_path = \"original_dataset/\"\n",
    "idTE = np.load(data_path + \"idTE.npy\")\n",
    "idTR = np.load(data_path + \"idTR.npy\")\n",
    "labelTE = np.load(data_path + \"labelTE.npy\")\n",
    "labelTR = np.load(data_path + \"labelTR.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the data from the mat file\n",
    "with h5py.File(mat_file, 'r') as f:\n",
    "    data = f[\"data\"]\n",
    "    data = pd.DataFrame(data).T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data.replace(0, data.mean()), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "X_test_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "for i in range(len(idTR)):\n",
    "    X_train_list.append(data.iloc[idTR[i] - 1]) #idTR is 1 indexed\n",
    "    X_test_list.append(data.iloc[idTE[i] - 1])  #idTE is 1 indexed\n",
    "    y_train_list.append(labelTR[i])\n",
    "    y_test_list.append(labelTE[i])\n",
    "\n",
    "X_train_arr = np.array(X_train_list)\n",
    "X_test_arr = np.array(X_test_list)\n",
    "y_train_arr = np.array(y_train_list)\n",
    "y_test_arr = np.array(y_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_4 = idTR[3]\n",
    "# for i in range(5):\n",
    "#     if i != 3:\n",
    "#         common_elements = set(fold_4) & set(idTR[i])\n",
    "#         num_common_elements = len(common_elements)\n",
    "#         print(f\"The two lists have {num_common_elements} common elements: {common_elements}\")\n",
    "fold_4_test = idTE[3]\n",
    "for i in range(4):\n",
    "    if i != 3:\n",
    "        common_elements = set(fold_4_test) & set(idTR[i])\n",
    "        num_common_elements = len(common_elements)\n",
    "        print(f\"The two lists have {num_common_elements} common elements: {common_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=13)\n",
    "\n",
    "X_train_arr_reshaped = X_train_arr.reshape(-1,26)\n",
    "X_test_arr_reshaped = X_test_arr.reshape(-1,26)\n",
    "print(X_train_arr_reshaped.shape)\n",
    "\n",
    "pca.fit(X_train_arr_reshaped)\n",
    "X_train_arr = pca.transform(X_train_arr_reshaped)\n",
    "X_test_arr = pca.transform(X_test_arr_reshaped)\n",
    "X_train_arr = X_train_arr.reshape(5,4535,13)\n",
    "X_test_arr = X_test_arr.reshape(5,1134,13)\n",
    "\n",
    "# X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr.shape, X_test_arr.shape, y_train_arr.shape, y_test_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net for binary classification 5x32x64x32x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# Convert numpy arrays or pandas DataFrames to PyTorch tensors if needed\n",
    "X_train_tens = torch.tensor(X_train_arr, dtype=torch.float32)\n",
    "y_train_tens = torch.tensor(y_train_arr, dtype=torch.long)\n",
    "\n",
    "# Defining a simple neural network class for binary classification\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, activation=nn.Tanh()):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.activation = activation       # Arbitrary activation function\n",
    "        self.fc2 = nn.Linear(10, 5)\n",
    "        # self.fc3 = nn.Linear(64, 32)  \n",
    "        self.fc4 = nn.Linear(5, 1)# Output layer with single neuron (binary classification)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        # x = self.activation(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))  # Apply sigmoid activation for binary classification of final output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED) # Added seed for reproducibility for all the activation functions\n",
    "losses = [] #Might turn into dict to make it more readable\n",
    "for i in range(len(X_train_tens)):\n",
    "    # Initialize the neural network\n",
    "    input_size = X_train_tens[i].shape[1]\n",
    "    model = NeuralNet(input_size)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Prepare data for training using DataLoader\n",
    "    batch_size = 64\n",
    "    train_dataset = TensorDataset(X_train_tens[i], y_train_tens[i])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 15\n",
    "    temp_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(dim=1)  # Remove extra dimension for binary classification\n",
    "            loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "        temp_loss.append(running_loss / len(train_loader))\n",
    "    losses.append(temp_loss)\n",
    "\n",
    "    # Example: Make predictions\n",
    "    # Assuming X_test is your test data\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_train_tens[i])\n",
    "        predictions = (predictions > 0.5).int()  # Convert probabilities to binary predictions (0 or 1)\n",
    "\n",
    "    # Define the directory path\n",
    "    dir_path = './models/'\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(dir_path):\n",
    "        # If not, create the directory\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    #Saving model for later use\n",
    "    model_dir = './models/'\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    model_path = os.path.join(model_dir, f'fold{i}_binary_classification_model.pth')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i, loss in enumerate(losses):\n",
    "    # c = act_colors[f\"fold_{i}\"]\n",
    "    plt.plot(loss, \"-o\", label=f\"fold_{i}\")#, color = c)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs. Epoch for Different Activation Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "mcc_scores = []\n",
    "for i in range(len(X_train_tens)):\n",
    "    print(f\"Evaluating model on fold: {i}\")\n",
    "    # Load the trained model\n",
    "    input_size = input_size  # Assuming the input size based on X_train\n",
    "    model = NeuralNet(input_size)\n",
    "    # model.load_state_dict(torch.load('./models/binary_classification_model.pth'))  # Load the trained model state  (Windows)\n",
    "    model.load_state_dict(torch.load(f'models/fold{i}_binary_classification_model.pth'))  # Load the trained model state (MACos)\n",
    "\n",
    "\n",
    "    # Assuming X_test and y_test are your test data\n",
    "    X_train = X_train_tens[i].float()\n",
    "    y_train = y_train_tens[i].float()\n",
    "\n",
    "    # Prepare test dataset and dataloader\n",
    "    batch_size = 64\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "\n",
    "    # Evaluate the model on the test set using F1 score\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    #print(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate Matthews Correlation Coefficient (MCC)\n",
    "    mcc_tr = matthews_corrcoef(y_true, y_pred)\n",
    "    mcc_scores.append(mcc_tr)\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Training: MCC-score: {mcc_tr}, check against the test set for overfitting\")\n",
    "\n",
    "print(f\"Mean MCC score on training set: {np.mean(mcc_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "mcc_scores = []\n",
    "all_metrics = {}\n",
    "all_confusion_matrices = {}\n",
    "for i in range(len(X_train_tens)):\n",
    "    print(f\"Evaluating model on fold: {i}\")\n",
    "    # Load the trained model\n",
    "    input_size = input_size  # Assuming the input size based on X_train\n",
    "    model = NeuralNet(input_size)\n",
    "    # model.load_state_dict(torch.load('./models/binary_classification_model.pth'))  # Load the trained model state  (Windows)\n",
    "    model.load_state_dict(torch.load(f'models/fold{i}_binary_classification_model.pth'))  # Load the trained model state (MACos)\n",
    "\n",
    "\n",
    "    # Assuming X_test and y_test are your test data\n",
    "    X_test = torch.tensor(X_test_arr[i], dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test_arr[i], dtype=torch.float32)\n",
    "\n",
    "    # Prepare test dataset and dataloader\n",
    "    batch_size = 64\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle for testing\n",
    "\n",
    "    # Evaluate the model on the test set using F1 score\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    #print(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    #print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # Calculate Matthews Correlation Coefficient (MCC)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    #print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "    # Compute accuracy, precision and recall\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')  # Change average as needed\n",
    "    recall = recall_score(y_true, y_pred, average='binary')  # Change average as needed\n",
    "\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    #print(\"Confusion Matrix:\", conf_matrix)\n",
    "\n",
    "    # Store the metrics in a dictionary for easy plotting\n",
    "    metrics = {'F1 Score': f1, 'MCC': mcc, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall}\n",
    "    \n",
    "    all_metrics[f\"fold_{i}\"] = metrics\n",
    "    all_confusion_matrices[f\"fold_{i}\"] = conf_matrix\n",
    "\n",
    "    \n",
    "    print(f\"Testing: {metrics['MCC']}\")\n",
    "    mcc_scores.append(metrics['MCC'])\n",
    "\n",
    "    # Define the directory path\n",
    "    dir_path = './models/'\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(dir_path):\n",
    "        # If not, create the directory\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join(dir_path, f'fold{i}_binary_classification_model.pth')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Mean MCC on testset: {np.mean(mcc_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the all_metrics dictionary to a DataFrame\n",
    "data = pd.DataFrame(all_metrics)\n",
    "# Reset the index to make 'Metrics' a column\n",
    "data = data.reset_index().rename(columns={'index': 'Metrics'})\n",
    "\n",
    "\n",
    "data = pd.melt(data, id_vars='Metrics', var_name='Activation Function', value_name='Value')\n",
    "\n",
    "data = data.set_index(['Metrics', 'Activation Function']).Value\n",
    "# colors = [act_colors[act_name] for act_name in all_metrics.keys()]\n",
    "colors = [\"orange\", \"red\", \"blue\", \"green\"]\n",
    "data.unstack().plot(kind='bar', stacked=False, color = colors)\n",
    "plt.ylim(0.6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test[y_test == 0]))\n",
    "print(len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "for i in range(len(X_train_tens)):\n",
    "    # Assume you have a function `get_conf_matrix` that returns the confusion matrix for a given activation function\n",
    "    conf_matrix = all_confusion_matrices[f\"fold_{i}\"]\n",
    "\n",
    "    # Create a heatmap for the confusion matrix on the i-th subplot\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "\n",
    "    # Set the title, x-label, and y-label for the i-th subplot\n",
    "    axes[i].set_title(f'Confusion Matrix (fold_{i})')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
